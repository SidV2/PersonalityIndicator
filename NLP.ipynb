{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sidharthaverma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing all necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as regex\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#storing it in a dataframe\n",
    "dataf = pd.read_csv('mbti_1.csv')\n",
    "#checking whether the data frame loads or not\n",
    "dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'enfj', 'enfp', 'entj', 'entp', 'esfj', 'esfp', 'estj', 'estp', 'infj', 'infp', 'intj', 'intp', 'isfj', 'isfp', 'istj', 'istp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-211f4a0e43fb>:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  datafcopy[\"posts\"] = datafcopy[\"posts\"].str.replace(regexPatStopWords, '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>moments   sportscenter  top ten plays   pran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding  lack     posts  alarmingsex   boring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one     course    say  know   blessing   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear     enjoyed  conversation   day  esoteric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fired another silly misconception  approachin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ    moments   sportscenter  top ten plays   pran...\n",
       "1  ENTP   finding  lack     posts  alarmingsex   boring...\n",
       "2  INTP  good one     course    say  know   blessing   ...\n",
       "3  INTJ  dear     enjoyed  conversation   day  esoteric...\n",
       "4  ENTJ   fired another silly misconception  approachin..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing the data to store it in a optimized way in DB\n",
    "\n",
    "#Copy the original data-set\n",
    "datafcopy = dataf.copy();\n",
    "\n",
    "#Lowercasing\n",
    "datafcopy[\"posts\"] = datafcopy[\"posts\"].apply(lambda dataflowercase: dataflowercase.lower())\n",
    "\n",
    "#Remove links \n",
    "datafcopy[\"posts\"] = datafcopy[\"posts\"].apply(lambda LinksRemoval: regex.sub(r'https?:\\/\\/.*?[\\s+]', '', LinksRemoval))\n",
    "    \n",
    "\n",
    "#Remove stop-words\n",
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "stopWords.extend(['enfj', 'enfp', 'entj', 'entp', 'esfj', 'esfp', 'estj', 'estp', 'infj', 'infp', 'intj', 'intp', 'isfj', 'isfp', 'istj', 'istp'])\n",
    "print(stopWords)\n",
    "regexPatStopWords = r'\\b(?:{})\\b'.format('|'.join(stopWords))\n",
    "datafcopy[\"posts\"] = datafcopy[\"posts\"].str.replace(regexPatStopWords, '')\n",
    "\n",
    "\n",
    "\n",
    "#Remove non words\n",
    "datafcopy[\"posts\"] = datafcopy[\"posts\"].apply(lambda nonWordsRemoval: regex.sub(r'[^a-zA-Z\\s]','', nonWordsRemoval))\n",
    "\n",
    "(datafcopy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>moment sportscent top ten play prank lifechang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>find lack post alarmingsex bore posit often ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one cours say know bless curs absolut pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear enjoy convers day esoter gab natur univer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  moment sportscent top ten play prank lifechang...\n",
       "1  ENTP  find lack post alarmingsex bore posit often ex...\n",
       "2  INTP  good one cours say know bless curs absolut pos...\n",
       "3  INTJ  dear enjoy convers day esoter gab natur univer...\n",
       "4  ENTJ  fire anoth silli misconcept approach logic go ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def get_stemmed_text(corpus):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "datafcopy['posts'] = get_stemmed_text(datafcopy['posts'])\n",
    "(datafcopy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting Data\n",
    "datafcopy.to_csv(index=False)\n",
    "compression_output = dict(method='zip', archive_name='out.csv')  \n",
    "datafcopy.to_csv('out.zip', index=False, compression=compression_output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>type of encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>moment sportscent top ten play prank lifechang...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>find lack post alarmingsex bore posit often ex...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one cours say know bless curs absolut pos...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear enjoy convers day esoter gab natur univer...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  type of encoding\n",
       "0  INFJ  moment sportscent top ten play prank lifechang...                 8\n",
       "1  ENTP  find lack post alarmingsex bore posit often ex...                 3\n",
       "2  INTP  good one cours say know bless curs absolut pos...                11\n",
       "3  INTJ  dear enjoy convers day esoter gab natur univer...                10\n",
       "4  ENTJ  fire anoth silli misconcept approach logic go ...                 2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting MBTI personality (or target or Y feature) into numerical form using Label Encoding\n",
    "# encoding personality type\n",
    "#Define target and train to split training and testing data sets\n",
    "enc = LabelEncoder()\n",
    "datafcopy['type of encoding'] = enc.fit_transform(datafcopy['type'])\n",
    "target = datafcopy['type of encoding']\n",
    "datafcopy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 170083)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing the posts for the model and filtering Stop-words\n",
    "vect = CountVectorizer(stop_words='english') \n",
    "\n",
    "#Converting posts (or training or X feature) into numerical form by count vectorization\n",
    "train =  vect.fit_transform(datafcopy[\"posts\"])\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6940, 170083) (6940,) (1735, 170083) (1735,)\n",
      "1228     9\n",
      "1290    15\n",
      "6756     0\n",
      "1662     9\n",
      "3338     9\n",
      "        ..\n",
      "7292     9\n",
      "1086     9\n",
      "7435     2\n",
      "1843    11\n",
      "2530     3\n",
      "Name: type of encoding, Length: 6940, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dividing the model into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.20, stratify=target, random_state=42)\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41.79%\n"
     ]
    }
   ],
   "source": [
    "#Using Gradient Descent Algorithm\n",
    "sgd = SGDClassifier(max_iter=10, tol=None)\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "Y_pred = sgd.predict(X_test)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuraciesSGD = {}\n",
    "accuracySGD = accuracy_score(y_test, predictions)\n",
    "accuraciesSGD['Gradient Descent'] = accuracySGD * 100.0\n",
    "print(\"Accuracy: %.2f%%\" % (accuracySGD * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31.99%\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "accuraciesRF = {}\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state = 1)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracyRF = accuracy_score(y_test, predictions)\n",
    "accuraciesRF['Random Forest'] = accuracyRF * 100.0 \n",
    "print(\"Accuracy: %.2f%%\" % (accuracyRF * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31.99%\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "accuraciesLR = {}\n",
    "lr = LinearRegression()\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracyLR = accuracy_score(y_test, predictions)\n",
    "accuraciesLR['Linear Regression'] = accuracyLR * 100.0 \n",
    "print(\"Accuracy: %.2f%%\" % (accuracyLR * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.037542   0.         ... 0.         0.         0.        ]\n",
      " [0.1355488  0.04902924 0.11270733 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.05489534 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.03220009 0.         ... 0.04340406 0.         0.        ]]\n",
      "[11]\n"
     ]
    }
   ],
   "source": [
    "cntizer = CountVectorizer(analyzer=\"word\", max_features=1000) \n",
    "X_trainExample =  cntizer.fit_transform(datafcopy['posts'])\n",
    "tfizer = TfidfTransformer()\n",
    "X_tfidf =  tfizer.fit_transform(X_trainExample).toarray()\n",
    "print(X_tfidf)\n",
    "\n",
    "X = X_tfidf\n",
    "Y = datafcopy['type of encoding']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, stratify=target, random_state=42)\n",
    "\n",
    "\n",
    "sgd = SGDClassifier(max_iter=10, tol=None)\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "result = []\n",
    "my_post_text = \"This is dsdsdsdsdsdsdlfnklsdcmczfjksfsdf\"\n",
    "my_post = pd.DataFrame([[my_post_text]])\n",
    "my_post = [str (item) for item in my_post]\n",
    "\n",
    "my_X_cnt = cntizer.transform(my_post)\n",
    "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()\n",
    "\n",
    "Y_pred = sgd.predict(my_X_tfidf)\n",
    "\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
